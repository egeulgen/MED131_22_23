---
title: "Undergrad Biostatistics - R Training - Week XI"
author: "Ege Ulgen"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Linear Regression

## Rationale behind linear regression

We'll use the pre/post dataset for this exercise. This dataset contains simulated data for pre-intervention measurements (`pre`) for 20 individuals together with their post-intervention measurements (`post`).

```{r load_pre_posts}
pre_post_df <- read.csv("../data/pre_post_data.csv")
dim(pre_post_df)
head(pre_post_df, 3)
```

Let's visualize the scatter plot to investigate any relationship between `pre` and `post` measurements:

```{r scatter}
plot(post~pre, data = pre_post_df)
```

We can fit many lines with varying slope (and intercept,  which is kept constant here):

```{r lines, echo=FALSE}
plot(post~pre, data = pre_post_df, xlim = c(0, 9), ylim = c(0, 10))
# y = bx + a
abline(a = .4, b = .5, col = 1)
abline(a = .4, b = .7, col = 2)
abline(a = .4, b = 1, col = 3)
abline(a = .4, b = 2, col = 4)

legend("topleft", legend = c(.5, .7, 1, 2), title = "b", col = 1:4, cex = 1.2, bty = "n", lty = 1)
```

Our aim is to minimize the distance of the residuals to the line (residuals = errors):

```{r resid, echo=FALSE}
plot_residual_dist <- function(df, b, a =.4, col = 1) {
    plot(post~pre, data = df, main = paste0("b=", b))
    abline(a = a, b = b, col = col)
    segments(x0 = df$pre, y0 = df$post, x1 = df$pre, y1 = b * df$pre + a, col = "red")
}

par(mfrow = c(2, 2))
plot_residual_dist(pre_post_df, .5)
plot_residual_dist(pre_post_df, .7)
plot_residual_dist(pre_post_df, 1)
plot_residual_dist(pre_post_df, 2)
par(mfrow = c(1, 1))
```

The residuals should fluctuate around 0:

```{r residuals2, echo=FALSE}
plot_residual_vals <- function(df, b, a = .4) {
    preds <- b * df$pre + a
    res <- df$post - preds
    tmp <- round(max(abs(res)))
    plot(1:nrow(df), res, ylim = c(-tmp, tmp), main = paste0("b=", b))
    abline(h = 0, col = "red", lty = 2)
}

par(mfrow = c(2, 2))
plot_residual_vals(pre_post_df, 0.5)
plot_residual_vals(pre_post_df, 0.7)
plot_residual_vals(pre_post_df, 1)
plot_residual_vals(pre_post_df, 2)
par(mfrow = c(1, 1))
```

## Examples

### Simple Linear Regression

```{r simple}
fit_simple <- lm(post~pre, pre_post_df)
summary(fit_simple)

### prediction
# what is the estimated (predicted) 'post' value given a 'pre' value of 3.2?
0.4616 + 1.0177 * 3.2

# more compactly for multiple new data points
new_data <- data.frame(pre = c(3.2, 1.8, 8.2))
predict(fit_simple, new_data)
```

### Multiple Linear Regression

We'll use the prostate cancer dataset for this exercise. The main aim of collecting this data set was to inspect the associations between prostate-specific antigen (PSA) and prognostic clinical measurements in men with advanced prostate cancer. Data were collected on 97 men who were about to undergo radical prostectomy.

```{r load_prca}
prca_df <- read.csv("../data/prostate_cancer.csv")

dim(prca_df)
head(prca_df)

# fix factor (categorical) variables
prca_df$invasion <- as.factor(prca_df$invasion)
prca_df$Gleason <- as.factor(prca_df$Gleason)

# summary for all variables
summary(prca_df)
```

We will log-transform PSA (outcome of interest, dependent variable) so that it is normally distributed.

```{r psa_norm}
# check normality
hist(prca_df$PSA)
qqnorm(prca_df$PSA)
qqline(prca_df$PSA)

prca_df$logPSA <- log(prca_df$PSA)
hist(prca_df$logPSA)
qqnorm(prca_df$logPSA)
qqline(prca_df$logPSA)
```

```{r psa_models}
fit1 <- lm(logPSA~vol, data = prca_df)
summary(fit1)

# to make sense of the intercept
fit1_1 <- lm(logPSA~I(vol - min(vol)), data = prca_df)
summary(fit1_1)


fit2 <- lm(logPSA~vol + invasion, data = prca_df)
summary(fit2)

fit3 <- lm(logPSA~vol * invasion, data = prca_df)
summary(fit3)



fit4 <- lm(logPSA~vol + Gleason, data = prca_df)
summary(fit4)

prca_df$Gleason <- relevel(prca_df$Gleason, "7")
fit4_2 <- lm(logPSA~vol + Gleason, data = prca_df)
summary(fit4_2)
prca_df$Gleason <- relevel(prca_df$Gleason, "6")

fit5 <- lm(logPSA~I(vol - min(vol)) + invasion + Gleason, data = prca_df)
summary(fit5)
```

# Logistic Regression

The data we'll use is `birthwt` from the `MASS` package. The `birthwt` data frame has 189 rows and 10 columns. The data were collected at Baystate Medical Center, Springfield, Mass during 1986.

```{r bw_data}
# install.packages("MASS")
library(MASS)

data(birthwt) 
?birthwt

dim(birthwt)

head(birthwt)

# turn categorical variables into factor
birthwt$low <- as.factor(birthwt$low)
birthwt$race <- as.factor(birthwt$race)
birthwt$smoke <- as.factor(birthwt$smoke)
birthwt$ht <- as.factor(birthwt$ht)
birthwt$ui <- as.factor(birthwt$ui)

summary(birthwt)
```

We'll be using logistic regression to identify risk factors associated with low infant birth weight (birth weight less than 2.5 kg).

```{r bw_models}
fit6 <- glm(low~. - bwt, data = birthwt, family = binomial)
summary(fit6)

fit7 <- glm(low~lwt + race + smoke + ht, data = birthwt, family = binomial)
summary(fit7)

(exp(-0.0179) - 1) * 100
```

# Poisson Regression

We will use the `epilepsy` data from the package `HSAUR`. We'll only analyze the first period (4 treatment periods exist) and investigate how various factors affect the number of seizures (recorded in `seizure.rate`).

```{r pois}
library(HSAUR)

data("epilepsy")

head(epilepsy, 10)
summary(epilepsy)

## subset for the first period
epilepsy_1_df <- epilepsy[epilepsy$period == 1, ]

head(epilepsy_1_df, 10)
summary(epilepsy_1_df)
```

As usual, first perform exploratory data analysis:

```{r pois_eda}
# visually compare number of seizures at baseline and at 2 weeks
plot(epilepsy_1_df$base, epilepsy_1_df$seizure.rate, xlab = "baseline", ylab = "at 2 weeks")
cor(epilepsy_1_df$seizure.rate,epilepsy_1_df$base, method = "spearman")

# compare bw/ treatment groups
boxplot(epilepsy_1_df$seizure.rate~epilepsy_1_df$treatment)

# correlation with age?
plot(epilepsy_1_df$seizure.rate~epilepsy_1_df$age)
cor(epilepsy_1_df$seizure.rate,epilepsy_1_df$age, method = "spearman")
```

We can now build our Poisson regression model:

```{r pois_model}
min(epilepsy_1_df$base)
min(epilepsy_1_df$age)

pos_reg <- glm(seizure.rate ~ as.factor(treatment) + I(base - 6) + I(age - 18),
               data = epilepsy_1_df, family = poisson)
summary(pos_reg)

## A patient in placebo group, with 6 previous seizure, and aged 18 had 
# approximately 2 seizures on average in the first two weeks after the trial was started
exp(0.750838)

## With 95% confidence, it could be said that there was no difference between 
# placebo and progabide (p-value = 0.2). Negative estimate for beta1 indicates 
# lowered mean number of seizures for progabide, but the difference from placebo 
# was not significant.

## With 95% confidence, it could be said that previous number of seizures occurred 
# in the 8-week interval prior to the study start and mean seizure rate was 
# significantly associated (p-value < 2 × 10-16). One unit increase in previous 
# seizure is associated with approximately 2.6% increase in the mean number of 
# seizures in the first two weeks of the trial.
(exp(0.025736) - 1) * 100

## With 95% confidence, it could be said that age and mean number of seizures 
# was significantly associated (p-value = 2.66 × 10-9). One year increase in age 
# was associated with approximately 4.8% increase in the seizure rate in the 
# first two weeks of the trial.
(exp(0.046528) - 1) * 100
```